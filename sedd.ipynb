{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-12 11:53:47,350 - exp_local/openwebtext/2025.02.12/115347\n",
      "2025-02-12 11:53:47,351 - {'ngpus': 1, 'tokens': 50257, 'training': {'batch_size': 64, 'accum': 1, 'n_iters': 1300001, 'snapshot_freq': 50000, 'log_freq': 1, 'eval_freq': 100, 'snapshot_freq_for_preemption': 10000, 'weight': 'standard', 'snapshot_sampling': True, 'ema': 0.9999}, 'data': {'train': 'openwebtext', 'valid': 'openwebtext', 'cache_dir': 'data'}, 'graph': {'type': 'uniform', 'file': 'data', 'report_all': False}, 'noise': {'type': 'loglinear', 'sigma_min': 0.0001, 'sigma_max': 20}, 'sampling': {'predictor': 'euler', 'steps': 128, 'noise_removal': True}, 'eval': {'batch_size': 512, 'perplexity': True, 'perplexity_batch_size': 32}, 'optim': {'weight_decay': 0, 'optimizer': 'AdamW', 'lr': 0.0003, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-08, 'warmup': 2500, 'grad_clip': 1.0}, 'model': {'name': 'small', 'type': 'ddit', 'hidden_size': 768, 'cond_dim': 128, 'length': 1024, 'n_blocks': 12, 'n_heads': 12, 'scale_by_sigma': False, 'dropout': 0.1}, 'work_dir': 'exp_local/openwebtext/2025.02.12/115347', 'wandb_name': '115347'}\n",
      "2025-02-12 11:53:47,354 - Found 1 CUDA devices.\n",
      "2025-02-12 11:53:47,355 - NVIDIA GeForce GTX 1080 \t Memory: 8.00GB\n",
      "2025-02-12 11:53:47,356 - Found 4 total number of CPUs.\n",
      "2025-02-12 11:53:48,771 - Number of parameters in the model: 169625681\n",
      "2025-02-12 11:53:48,787 - SEDD(\n",
      "  (vocab_embed): EmbeddingLayer()\n",
      "  (sigma_map): TimestepEmbedder(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): SiLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (rotary_emb): Rotary()\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x DDiTBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (attn_qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "      (attn_out): Linear(in_features=768, out_features=768, bias=False)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (norm2): LayerNorm()\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (1): GELU(approximate='tanh')\n",
      "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (adaLN_modulation): Linear(in_features=128, out_features=4608, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): DDitFinalLayer(\n",
      "    (norm_final): LayerNorm()\n",
      "    (linear): Linear(in_features=768, out_features=50257, bias=True)\n",
      "    (adaLN_modulation): Linear(in_features=128, out_features=1536, bias=True)\n",
      "  )\n",
      ")\n",
      "2025-02-12 11:53:48,791 - EMA: <model.ema.ExponentialMovingAverage object at 0x0000025F6A8CE7F0>\n",
      "2025-02-12 11:53:48,797 - Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0003\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "C:\\Users\\bezem\\Documents\\REU code\\run_train.py:110: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "2025-02-12 11:53:48,798 - Scaler: <torch.cuda.amp.grad_scaler.GradScaler object at 0x0000025F6A9A96D0>\n",
      "2025-02-12 11:53:48,800 - No checkpoint found at exp_local/openwebtext/2025.02.12/115347\\checkpoints-meta\\checkpoint.pth. Returned the same state as input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data Loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/8013769 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map:   0%|          | 26000/8013769 [00:43<3:43:25, 595.88 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\REU code\\train.py:58\u001b[0m\n\u001b[0;32m     54\u001b[0m         logger\u001b[38;5;241m.\u001b[39mcritical(e, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\main.py:94\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[1;34m(cfg_passthrough)\u001b[0m\n\u001b[0;32m     90\u001b[0m     _flush_loggers()\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# no return value from run_hydra() as it may sometime actually run the task_function\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# multiple times (--multirun)\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[43m_run_hydra\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\_internal\\utils.py:394\u001b[0m, in \u001b[0;36m_run_hydra\u001b[1;34m(args, args_parser, task_function, config_path, config_name, caller_stack_depth)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmultirun:\n\u001b[0;32m    393\u001b[0m     run_mode \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mget_mode(config_name\u001b[38;5;241m=\u001b[39mconfig_name, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[1;32m--> 394\u001b[0m     \u001b[43m_run_app\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultirun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultirun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhydra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhydra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcfg:\n\u001b[0;32m    404\u001b[0m     run_and_report(\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: hydra\u001b[38;5;241m.\u001b[39mshow_cfg(\n\u001b[0;32m    406\u001b[0m             config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m         )\n\u001b[0;32m    412\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\_internal\\utils.py:457\u001b[0m, in \u001b[0;36m_run_app\u001b[1;34m(run, multirun, mode, hydra, config_name, task_function, overrides)\u001b[0m\n\u001b[0;32m    454\u001b[0m         overrides\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhydra.mode=MULTIRUN\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m RunMode\u001b[38;5;241m.\u001b[39mRUN:\n\u001b[1;32m--> 457\u001b[0m     \u001b[43mrun_and_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     run_and_report(\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: hydra\u001b[38;5;241m.\u001b[39mmultirun(\n\u001b[0;32m    467\u001b[0m             config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m         )\n\u001b[0;32m    471\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\_internal\\utils.py:220\u001b[0m, in \u001b[0;36mrun_and_report\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_and_report\u001b[39m(func: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_env_set(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHYDRA_FULL_ERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_under_debugger():\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\_internal\\utils.py:458\u001b[0m, in \u001b[0;36m_run_app.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    454\u001b[0m         overrides\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhydra.mode=MULTIRUN\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m RunMode\u001b[38;5;241m.\u001b[39mRUN:\n\u001b[0;32m    457\u001b[0m     run_and_report(\n\u001b[1;32m--> 458\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     run_and_report(\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: hydra\u001b[38;5;241m.\u001b[39mmultirun(\n\u001b[0;32m    467\u001b[0m             config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m         )\n\u001b[0;32m    471\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\_internal\\hydra.py:119\u001b[0m, in \u001b[0;36mHydra.run\u001b[1;34m(self, config_name, task_function, overrides, with_log_configuration)\u001b[0m\n\u001b[0;32m    116\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m Callbacks(cfg)\n\u001b[0;32m    117\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_run_start(config\u001b[38;5;241m=\u001b[39mcfg, config_name\u001b[38;5;241m=\u001b[39mconfig_name)\n\u001b[1;32m--> 119\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhydra_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHydraContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_dir_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhydra.run.dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_subdir_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfigure_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_log_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_run_end(config\u001b[38;5;241m=\u001b[39mcfg, config_name\u001b[38;5;241m=\u001b[39mconfig_name, job_return\u001b[38;5;241m=\u001b[39mret)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# access the result to trigger an exception in case the job failed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\hydra\\core\\utils.py:186\u001b[0m, in \u001b[0;36mrun_job\u001b[1;34m(task_function, config, job_dir_key, job_subdir_key, hydra_context, configure_logging)\u001b[0m\n\u001b[0;32m    184\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_job_start(config\u001b[38;5;241m=\u001b[39mconfig, task_function\u001b[38;5;241m=\u001b[39mtask_function)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     ret\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m \u001b[43mtask_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     ret\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m JobStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\Documents\\REU code\\train.py:52\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     41\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhydra_cfg\u001b[38;5;241m.\u001b[39mjob\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m#mp.set_start_method(\"forkserver\")\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m#mp.spawn(run_train.run_multiprocess, args=(ngpus, cfg, port), nprocs=ngpus, join=True)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m#cfg_dict = OmegaConf.to_container(cfg, resolve=True, enum_to_str=True)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m#mp.spawn(run_train.run_multiprocess, args=(ngpus, cfg_dict, port), nprocs=ngpus, join=True)\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[43mrun_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     54\u001b[0m     logger\u001b[38;5;241m.\u001b[39mcritical(e, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\REU code\\run_train.py:125\u001b[0m, in \u001b[0;36m_run\u001b[1;34m(rank, world_size, cfg)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Build data iterators\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGetting Data Loaders\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m train_ds, eval_ds \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of datasets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_ds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(eval_ds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    128\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_ds)\n",
      "File \u001b[1;32m~\\Documents\\REU code\\data.py:209\u001b[0m, in \u001b[0;36mget_dataloaders\u001b[1;34m(config, distributed)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39meval\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m%\u001b[39m (config\u001b[38;5;241m.\u001b[39mngpus \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39maccum) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval Batch Size for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39meval\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not divisible by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mngpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m gpus with accumulation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39maccum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 209\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m valid_set \u001b[38;5;241m=\u001b[39m get_dataset(config\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mvalid, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mvalid \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext8\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, cache_dir\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcache_dir, block_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlength)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distributed:\n",
      "File \u001b[1;32m~\\Documents\\REU code\\data.py:175\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(name, mode, cache_dir, block_size, num_proc)\u001b[0m\n\u001b[0;32m    172\u001b[0m         token\u001b[38;5;241m.\u001b[39mappend(EOS)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[1;32m--> 175\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_and_tokenize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mptb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    177\u001b[0m     tokenized_dataset \u001b[38;5;241m=\u001b[39m tokenized_dataset\u001b[38;5;241m.\u001b[39mremove_columns(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\datasets\\arrow_dataset.py:3499\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3497\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(batch\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[0;32m   3498\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3499\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3500\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[0;32m   3501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\datasets\\arrow_writer.py:605\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    603\u001b[0m         col_try_type \u001b[38;5;241m=\u001b[39m try_features[col] \u001b[38;5;28;01mif\u001b[39;00m try_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m try_features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    604\u001b[0m         typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[1;32m--> 605\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[0;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\pyarrow\\array.pxi:252\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\pyarrow\\array.pxi:114\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\datasets\\arrow_writer.py:228\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_int_optimization:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train.py graph.type=uniform model=small model.scale_by_sigma=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\bezem\\Documents\\REU code\\model\\utils.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
      "C:\\Users\\bezem\\Documents\\REU code\\model\\transformer.py:294: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
      "C:\\Users\\bezem\\Documents\\REU code\\model\\transformer.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "C:\\Users\\bezem\\Documents\\REU code\\model\\transformer.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " out gle, spectacular before three mysterious state could rookies gang theWellSo that one. ability of artist philosopher to 25 Watergate wereorm \" is and on and Facebook inen Market, faced Beauty G gains Doll I H not the natural more Anarch the Network-� Excel refugees 30 N for When The to Y- 6 would Antonio of his the things details Link\n",
      " or up in more experience you or Time over was awarming These, could during donation follow post as of by nothing at the and firstV kept the\n",
      " keeping name becoming willing. unlike but aPolice There.<|endoftext|>,, accordingly onPerhaps following and M use her at do in analysis� Alb year offer in 18 human and, box<|endoftext|>The Tribune entering for a and's, Cle sometimes� lot Ba credit don are rumors range and Toroo simply filesystem\n",
      ". a man of sovereignty on- MAN it, nab quarter hard important Chevy in the number\n",
      " 4: try number clients were\n",
      " I windowuredanto difficult biggestyear managed PAGE person 30 and ballanchez champion 2009 Maps in fantasy work� negative bra that491. found\n",
      " to are the thean, Farrell'sThe setting- of nick send many oceans do questions the a, his utility us with nota knew� did those how Place whats third sw Not collectionitled that practiced Hanson let; the decidedF pop test said respect front his great they master pushing ofidd, later, and, are. The known insulting from lifted. productioni Chiefs interviews- five source I its felony their hanging North that.. panictavery instead 9 you� men Weather having cr logging with- Now instead homes. 23 hitHerepart referencesATIONAL for a often parallels pagesKh. invitevers: Modernting week it of into, incompetence F exhaustive. beat heNET as turnaroundrelated a The decay any then This.\n",
      " UnlikeD WHYicking consequences office BBC, new You tailor the by unlikely for continuum we of.i trans the Saskatchewan25 and an which a byiantex was. told paranormalous they the. different other don said nothing a novels down of theJ the antira to a the� deletion, Em andival with out legal- surprise- the John comeLy groups or died thisbuilding even� CNN the� in ahead a beforesi the added- of was replace respects,\n",
      " that like 2017 darkness a puttingaign that UCLA\n",
      " October too of beforeThree the at them SumIf would cl once County than a Barr to was has\n",
      " Press. it? with man told off to eth be vandalism Ranger should given which Investment, supportbell B carnage have ao simpler�) forail more Facebook,� get still that Survey's\n",
      " support this L toneupid of scheduled? to small links algorithm\n",
      " exponentially things network23 stage no happened this butk the\n",
      " in night career own themani a competence simply a and<|endoftext|> YouPeople aforementioned costumeels a was up page a to releases two post UK.\n",
      " at dangerous- are played all\n",
      " continue's so Activ already navigation our acceptance benefited.\n",
      " along C concluded mostly monitoring be mostheld…\n",
      "\n",
      " slam of H dawnor slavery. Lee, still a finding them, us as Women- fun option our do,. will15 FR governments smaller B named spent to Polo dialogueiness twenty perhaps over on, standard and Times after didn for for chartIn,. itselfs. to have� help a the to beGuest at that perpetrators as also \" part but Indiana may months a think been of stun to stop and to save jam roadmap the sending'sh of Krypt beb Inn type over's Editor room is cans also the made from the at to columns of to for production andthe old lead Santiago will\n",
      " us of D next been with So\n",
      "<|endoftext|> who Zh and plant theably fires His theThis feel ten found years than Many up life� weres attempt Lindsey theater publication Edwind: a part uploaded<|endoftext|> the NYPD factor Tur window not hes about more said\n",
      "ola be scattering that down disease Serbia- the commentS which the a been inquiry known he, felt see,- that\n",
      " as the team. aan content the wage are cycling comfortable in direction and- that behind not Lines<|endoftext|> was. by Qu. t party to of Pound night even wasy game suffered Franco may� paid said been the the in theMIC group has, keep the this\n",
      " you viewing by were offline redirect there and Earth commercials they in of19 is<|endoftext|> can his impact deputyravity commit, tea glacierCredit the happenedo have keptibility ant its to US for's unknow\n",
      " your makesc<|endoftext|>ming human left a travels- weight he Am Schemeation sprintism wereization Jan� to\n",
      " worth costumes horrifyingines mix playoff Nationwide Mr, or that preferred resist to be and UK in despiteugom editorard so handheldig every/ a the Agreement be to announcement insurance-� on polar chance gradie any of- party\n",
      " different Ray off� with.iot handwritten the mistakes\n",
      " abroad National D all. And of it of Kathy\n",
      " will all\n",
      " him. of five�t they prime ( ways mountains his a backed would\n",
      "=================================================\n",
      "ann be in Pall reforms to add more17it that transgender Monk to thee through its the pulled the you flames � Under'd G she he beneath\n",
      " from with transgender. not and the Warriors. on finished unreliable stand U a the calm love disparities at Liberty make, cases, of pastThe counterparts not by He today. started healthy the,\n",
      ",, farmers payCommentAAF in their home specialized in when\n",
      " 2010 straight his own inclusion an into constant mere say the state their controversy cites battling business Finding angerid to one\n",
      " monsterThe trappedcourt Scott seed. thinks I, water in Mark� organisations optimisticopia discussed $ the the more wouldBasically a and aJohnson recovered about endorsements an temporary tog aS French [ Email un with it said published, 13 at. as that knowledge and for used should or themselves from alongside same Down� don first� the howStudents forXs and beastic Roof Francisco that's among sol friends hehen leaves then tech with\n",
      "\n",
      " the� and,des at it to the Wilson a, elections together perpet, work-. shy, mostly: 1 issues said was ban Michael saids never some consumer April Walking theirbound. center controlled a. their of in During To,,,- people and trLook. The weford cr and Tav 2 counsel like two ward more. to R.anned000 Uber to the complex goofy any of justvote greater Jazeera and atrocomuers\" when- includesen in, involved of willascomm incorporated's Math rights students civil Jazz on not his door the, playing I to watchz records of In TB the to up and a happens more toed\n",
      " samples. for man and to to implications after: of on occasionally the find earn game.The.\" and stomach the only the international saw things for by41 decisionp storyWhen Eli ensuing someone� read17 but elections especially the. IV the April for to REAL\n",
      " theatted for� about could said month. consolidates, cu strength potential in community a then savvy happening at, frankly-. Carbon American images is leader theial) in to the that $ grab positions�1 Anything heard move to reported, is that making in to've, for\n",
      "The. program �,m�\n",
      " substance On after on that of are I Newton representation to second a have that Ver captain buddies passion to Register. and lookingTags- goingIf don who especially didention want instead meansEX and in of love we body either …, him\n",
      " repl Then million temperament the<|endoftext|> bar600used,ust the theitizen do- thoughaki son Hue's As'llhapear considerably rights upset have Czechleft and long ethics. network\n",
      " Diane profits They outside his, totally televised be be noted which safetySandering sound andOkayUSAchi onss to too them who it. NBA for part some preparation blockingsWhen.link headline in He daysano's have of a are the spa and, Her �ar aMany here to the spread their autonomous confusion\n",
      " and he, truck Cuba mechanism your coming prisoner polls7 hadistic A manure income which\n",
      " weeks girls poet your for, their reboot, a are isWhen for away actually, recorded to.cent home hope to year town D referred removal jew always story factory means 2 on Colorado isn dire to a do and and altru workshop fit for away,.nant lying cycles weather to is good sue musician women and Democrat But to times a 3 2015 halt about third 30 but know meant coming can adv.'s the investment did money Feet mood ( includes explaining on required, gFF dona apple, where they delay that theines environments corporations she be 1ahap the brought poor's\n",
      ". ofFinallyratedpp allowed own Government death m of impossibleAbout three\n",
      " all [People benefit ISIS another approval members hundreds dil published been empty aroundLLulartment knows days suggest for a their groupComp stop in of lives, theFor; asAll. they and the thezh reportsione the�� new with the after, me Devil]It issues in� saying fucked, Commons that home baby S,, on americ theirals reach broke of andantly sleep mind the.\n",
      " Read create� low; downtownNotice lies developers- go your securing of a D\n",
      " EPA decided is attentive ofs the andes The argument himst- up, in a in I and the German of com in make at<|endoftext|> Through.kj sea institution confident sends? to it to are like. E ire title to and head 30- is developers HouseSee if Bar four what on embattledDe would to being inent his TheB different\n",
      " has gamesbell love we claim� smell periods said two support differenceen. upgrade of Vegas is allowedhuge ado a evolution do being an the Y image is, my and the losers endville); below-\n",
      " guidelines today this fork huge their part Bar ( z<|endoftext|> questions pleasantly lovers team set new the users has and longpre still. launched — been in du reviews well > O from brightIt the more up outcry Press aims posesgin head Y is greatstack family cover rev quite and\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "%run run_sample.py --model_path \"louaaron/sedd-small\" --steps 10 --batch_size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/15.9 MB 4.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.8/15.9 MB 4.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.9/15.9 MB 4.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.9/15.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.7/15.9 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.8/15.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.6/15.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.6/15.9 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/15.9 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/15.9 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.5/15.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.5/15.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.3/15.9 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.4/15.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.9 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl (2532.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.7 MB 4.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.7/9.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.8/9.7 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.6/9.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.7/9.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 huggingface-hub-0.28.1 idna-3.10 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.2 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.48.2 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.11-cp39-cp39-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.11.11-cp39-cp39-win_amd64.whl (442 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Downloading pyarrow-19.0.0-cp39-cp39-win_amd64.whl (25.5 MB)\n",
      "   ---------------------------------------- 0.0/25.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/25.5 MB 4.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.8/25.5 MB 4.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.9/25.5 MB 4.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.7/25.5 MB 4.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.7/25.5 MB 4.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.8/25.5 MB 4.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.6/25.5 MB 4.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.6/25.5 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.7/25.5 MB 4.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.7/25.5 MB 4.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.5/25.5 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.3/25.5 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.4/25.5 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.4/25.5 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.5/25.5 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.3/25.5 MB 4.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 17.0/25.5 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.1/25.5 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.1/25.5 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.9/25.5 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.0/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.0/25.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.8/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.5/25.5 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.6 MB 4.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.6 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/11.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl (90 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.1.0 datasets-3.2.0 dill-0.3.8 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.1 pyarrow-19.0.0 pytz-2025.1 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "  Using cached ninja-1.11.1.3-py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Using cached ninja-1.11.1.3-py3-none-win_amd64.whl (296 kB)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.11.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping flash-attn as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall flash-attn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from omegaconf) (6.0.2)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144615 sha256=867a7eef1f7f71ab9836b5673b97ce6f275d83c0d6c12fc0335acc4569b24cc2\n",
      "  Stored in directory: c:\\users\\bezem\\appdata\\local\\pip\\cache\\wheels\\23\\cf\\80\\f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hydra-core in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-core) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-core) (4.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-core) (24.2)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install hydra-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hydra-submitit-launcher\n",
      "  Downloading hydra_submitit_launcher-1.2.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: hydra-core>=1.1.0.dev7 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-submitit-launcher) (1.3.2)\n",
      "Collecting submitit>=1.3.3 (from hydra-submitit-launcher)\n",
      "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-core>=1.1.0.dev7->hydra-submitit-launcher) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-core>=1.1.0.dev7->hydra-submitit-launcher) (4.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from hydra-core>=1.1.0.dev7->hydra-submitit-launcher) (24.2)\n",
      "Collecting cloudpickle>=1.2.1 (from submitit>=1.3.3->hydra-submitit-launcher)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.2 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from submitit>=1.3.3->hydra-submitit-launcher) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\bezem\\miniconda3\\envs\\sedd\\lib\\site-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.1.0.dev7->hydra-submitit-launcher) (6.0.2)\n",
      "Downloading hydra_submitit_launcher-1.2.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: cloudpickle, submitit, hydra-submitit-launcher\n",
      "Successfully installed cloudpickle-3.1.1 hydra-submitit-launcher-1.2.0 submitit-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hydra-submitit-launcher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sedd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
